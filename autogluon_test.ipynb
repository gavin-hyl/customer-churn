{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Caltech\\CS 155\\project1\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "# import autogluon.tabular as agtb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240209_054805\"\n",
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 3600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels\\ag-20240209_054805/ds_sub_fit/sub_fit_ho.\n",
      "2024-02-08 21:48:06,406\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240209_054805/ds_sub_fit/sub_fit_ho\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          32\n",
      "Memory Avail:       21.60 GB / 31.75 GB (68.0%)\n",
      "Disk Space Avail:   140.28 GB / 276.64 GB (50.7%)\n",
      "===================================================\n",
      "Train Data Rows:    4749\n",
      "Train Data Columns: 19\n",
      "Label Column:       Discontinued\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22121.26 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.43 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  2 | ['MonthlyCharges', 'TotalCharges']\n",
      "\t\t('int', [])    :  2 | ['SeniorCitizen', 'tenure']\n",
      "\t\t('object', []) : 15 | ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 10 | ['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', ...]\n",
      "\t\t('float', [])     :  2 | ['MonthlyCharges', 'TotalCharges']\n",
      "\t\t('int', [])       :  1 | ['tenure']\n",
      "\t\t('int', ['bool']) :  6 | ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t19 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.19 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 599.73s of the 899.8s of remaining time.\n",
      "\t-0.4205\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 594.68s of the 894.75s of remaining time.\n",
      "\t-0.4331\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 594.62s of the 894.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t-0.3686\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.62s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 571.08s of the 871.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t-0.3688\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.25s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 565.34s of the 865.41s of remaining time.\n",
      "\t-0.3875\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.47s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 563.57s of the 863.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.04%)\n",
      "\t-0.3662\t = Validation score   (-root_mean_squared_error)\n",
      "\t45.58s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 513.66s of the 813.74s of remaining time.\n",
      "\t-0.3898\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.05s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 512.17s of the 812.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t-0.371\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.55s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 490.93s of the 791.0s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.05%)\n",
      "\t-0.3716\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 485.26s of the 785.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t-0.4122\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.62s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 461.99s of the 762.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.08%)\n",
      "\t-0.3763\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.87s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 454.55s of the 754.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.04%)\n",
      "\t-0.367\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 448.16s of the 748.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t-0.4284\t = Validation score   (-root_mean_squared_error)\n",
      "\t40.06s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 403.68s of the 703.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.04%)\n",
      "\t-0.3704\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.34s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 396.78s of the 696.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t-0.3701\t = Validation score   (-root_mean_squared_error)\n",
      "\t33.01s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 359.1s of the 659.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.15%)\n",
      "\t-0.3685\t = Validation score   (-root_mean_squared_error)\n",
      "\t29.14s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 325.2s of the 625.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t-0.3673\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.89s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 318.97s of the 619.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t-0.4579\t = Validation score   (-root_mean_squared_error)\n",
      "\t86.53s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 228.12s of the 528.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.29%)\n",
      "\t-0.3788\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.73s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 221.04s of the 521.11s of remaining time.\n",
      "\t-0.3899\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.33s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 219.36s of the 519.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t-0.3664\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.49s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 198.51s of the 498.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t-0.3694\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.08s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 187.07s of the 487.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.16%)\n",
      "\t-0.3679\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.93s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 177.43s of the 477.5s of remaining time.\n",
      "\t-0.3856\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.48s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 175.6s of the 475.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.07%)\n",
      "\t-0.3722\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.69s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 168.55s of the 468.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t-0.3695\t = Validation score   (-root_mean_squared_error)\n",
      "\t33.24s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 130.78s of the 430.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.05%)\n",
      "\t-0.3683\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 125.06s of the 425.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t-0.482\t = Validation score   (-root_mean_squared_error)\n",
      "\t99.18s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 21.4s of the 321.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.06%)\n",
      "\t-0.368\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.77s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 14.87s of the 314.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t-0.513\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.52s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 295.44s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.395, 'NeuralNetFastAI_r191_BAG_L1': 0.158, 'NeuralNetTorch_r79_BAG_L1': 0.132, 'LightGBM_r130_BAG_L1': 0.132, 'LightGBM_BAG_L1': 0.105, 'NeuralNetFastAI_BAG_L1': 0.079}\n",
      "\t-0.3633\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 294.57s of the 294.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.07%)\n",
      "\t-0.3653\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.01s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 288.19s of the 287.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.07%)\n",
      "\t-0.3664\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.0s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 281.82s of the 281.53s of remaining time.\n",
      "\t-0.3687\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.59s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 275.74s of the 275.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.11%)\n",
      "\t-0.3633\t = Validation score   (-root_mean_squared_error)\n",
      "\t60.09s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 210.9s of the 210.61s of remaining time.\n",
      "\t-0.366\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 209.38s of the 209.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.04%)\n",
      "\t-0.367\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.57s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 189.48s of the 189.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.13%)\n",
      "\t-0.3671\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.19s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 180.83s of the 180.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t-0.3994\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.48s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 161.93s of the 161.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.22%)\n",
      "\t-0.3701\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.49s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 146.94s of the 146.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.11%)\n",
      "\t-0.3635\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.05s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 132.48s of the 132.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t-0.4303\t = Validation score   (-root_mean_squared_error)\n",
      "\t27.48s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 100.64s of the 100.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.10%)\n",
      "\t-0.367\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.33s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 91.98s of the 91.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.04%)\n",
      "\t-0.3682\t = Validation score   (-root_mean_squared_error)\n",
      "\t30.77s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 56.88s of the 56.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.38%)\n",
      "\t-0.364\t = Validation score   (-root_mean_squared_error)\n",
      "\t45.51s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 6.25s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r177_BAG_L2': 0.212, 'ExtraTreesMSE_BAG_L2': 0.192, 'XGBoost_BAG_L2': 0.173, 'NeuralNetFastAI_BAG_L2': 0.135, 'CatBoost_BAG_L1': 0.096, 'CatBoost_BAG_L2': 0.077, 'NeuralNetFastAI_r191_BAG_L2': 0.077, 'NeuralNetFastAI_r191_BAG_L1': 0.038}\n",
      "\t-0.3616\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 894.04s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.27s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.14s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.47s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t4.12s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.05s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "d:\\Caltech\\CS 155\\project1\\.conda\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\tStopping at the best epoch learned earlier - 7.\n",
      "\t1.31s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.07s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\t1.2s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.26s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\t0.15s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1_FULL ...\n",
      "\t4.68s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\t0.33s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "d:\\Caltech\\CS 155\\project1\\.conda\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\tStopping at the best epoch learned earlier - 23.\n",
      "\t5.63s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\t2.27s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\t0.3s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1_FULL ...\n",
      "\t10.51s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\t0.25s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.33s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\t2.1s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1_FULL ...\n",
      "d:\\Caltech\\CS 155\\project1\\.conda\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\tStopping at the best epoch learned earlier - 14.\n",
      "\t0.78s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_r13_BAG_L1_FULL ...\n",
      "\t0.62s\t = Training   runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.48s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_r188_BAG_L1_FULL ...\n",
      "\t0.27s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1_FULL ...\n",
      "d:\\Caltech\\CS 155\\project1\\.conda\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\tStopping at the best epoch learned earlier - 16.\n",
      "\t6.23s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_r89_BAG_L1_FULL ...\n",
      "\t0.05s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1_FULL ...\n",
      "\t9.9s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_r130_BAG_L1_FULL ...\n",
      "\t0.15s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1_FULL ...\n",
      "\t2.08s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.395, 'NeuralNetFastAI_r191_BAG_L1': 0.158, 'NeuralNetTorch_r79_BAG_L1': 0.132, 'LightGBM_r130_BAG_L1': 0.132, 'LightGBM_BAG_L1': 0.105, 'NeuralNetFastAI_BAG_L1': 0.079}\n",
      "\t0.82s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t0.19s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.15s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t5.59s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t4.78s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "d:\\Caltech\\CS 155\\project1\\.conda\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\tStopping at the best epoch learned earlier - 6.\n",
      "\t1.27s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.12s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\t0.35s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t0.41s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_r177_BAG_L2_FULL ...\n",
      "\t0.56s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2_FULL ...\n",
      "\t2.18s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_r131_BAG_L2_FULL ...\n",
      "\t0.53s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2_FULL ...\n",
      "d:\\Caltech\\CS 155\\project1\\.conda\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\tStopping at the best epoch learned earlier - 4.\n",
      "\t1.34s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_r9_BAG_L2_FULL ...\n",
      "\t8.15s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_r177_BAG_L2': 0.212, 'ExtraTreesMSE_BAG_L2': 0.192, 'XGBoost_BAG_L2': 0.173, 'NeuralNetFastAI_BAG_L2': 0.135, 'CatBoost_BAG_L1': 0.096, 'CatBoost_BAG_L2': 0.077, 'NeuralNetFastAI_r191_BAG_L2': 0.077, 'NeuralNetFastAI_r191_BAG_L1': 0.038}\n",
      "\t0.27s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 78.07s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240209_054805/ds_sub_fit/sub_fit_ho\")\n",
      "Leaderboard on holdout data from dynamic stacking:\n",
      "                               model  holdout_score  score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0          CatBoost_r137_BAG_L1_FULL      -0.356117  -0.366429  root_mean_squared_error        0.010993            NaN   2.095382                 0.010993                     NaN           2.095382            1       True         21\n",
      "1               CatBoost_BAG_L1_FULL      -0.356231  -0.366170  root_mean_squared_error        0.015529            NaN   4.121390                 0.015529                     NaN           4.121390            1       True          6\n",
      "2           LightGBM_r96_BAG_L1_FULL      -0.356308  -0.367287  root_mean_squared_error        0.017000            NaN   0.304148                 0.017000                     NaN           0.304148            1       True         17\n",
      "3             LightGBMXT_BAG_L1_FULL      -0.356382  -0.368557  root_mean_squared_error        0.018990            NaN   0.270348                 0.018990                     NaN           0.270348            1       True          3\n",
      "4            XGBoost_r89_BAG_L1_FULL      -0.356955  -0.368256  root_mean_squared_error        0.027001            NaN   0.045830                 0.027001                     NaN           0.045830            1       True         27\n",
      "5           CatBoost_r13_BAG_L1_FULL      -0.357354  -0.367864  root_mean_squared_error        0.009685            NaN   0.623030                 0.009685                     NaN           0.623030            1       True         23\n",
      "6           WeightedEnsemble_L3_FULL      -0.357477  -0.361562  root_mean_squared_error        1.348212            NaN  68.509185                 0.010999                     NaN           0.267197            3       True         46\n",
      "7           WeightedEnsemble_L2_FULL      -0.357546  -0.363336  root_mean_squared_error        0.177171            NaN  16.858074                 0.010000                     NaN           0.821465            2       True         31\n",
      "8               CatBoost_BAG_L2_FULL      -0.357989  -0.363340  root_mean_squared_error        1.111539            NaN  63.817333                 0.020998                     NaN           4.781000            2       True         35\n",
      "9          CatBoost_r177_BAG_L1_FULL      -0.358045  -0.367016  root_mean_squared_error        0.022507            NaN   0.147361                 0.022507                     NaN           0.147361            1       True         12\n",
      "10         LightGBM_r131_BAG_L1_FULL      -0.358147  -0.370419  root_mean_squared_error        0.022002            NaN   0.334189                 0.022002                     NaN           0.334189            1       True         14\n",
      "11         LightGBM_r130_BAG_L1_FULL      -0.358167  -0.367977  root_mean_squared_error        0.016001            NaN   0.154231                 0.016001                     NaN           0.154231            1       True         29\n",
      "12         ExtraTreesMSE_BAG_L2_FULL      -0.358724  -0.365974  root_mean_squared_error        1.166209            NaN  60.171434                 0.075669                0.295615           1.135101            2       True         36\n",
      "13  NeuralNetFastAI_r145_BAG_L1_FULL      -0.358792  -0.369521  root_mean_squared_error        0.052544            NaN   6.234540                 0.052544                     NaN           6.234540            1       True         26\n",
      "14            LightGBMXT_BAG_L2_FULL      -0.358849  -0.365285  root_mean_squared_error        1.112545            NaN  59.221338                 0.022004                     NaN           0.185005            2       True         32\n",
      "15  NeuralNetFastAI_r191_BAG_L1_FULL      -0.358937  -0.370097  root_mean_squared_error        0.051511            NaN   5.632577                 0.051511                     NaN           5.632577            1       True         15\n",
      "16               XGBoost_BAG_L1_FULL      -0.358978  -0.371579  root_mean_squared_error        0.016998            NaN   0.067357                 0.016998                     NaN           0.067357            1       True          9\n",
      "17              LightGBM_BAG_L1_FULL      -0.359647  -0.368838  root_mean_squared_error        0.010999            NaN   0.140558                 0.010999                     NaN           0.140558            1       True          4\n",
      "18       RandomForestMSE_BAG_L2_FULL      -0.359840  -0.368740  root_mean_squared_error        1.211055            NaN  64.621605                 0.120514                0.372908           5.585272            2       True         34\n",
      "19           CatBoost_r9_BAG_L2_FULL      -0.359999  -0.363987  root_mean_squared_error        1.121541            NaN  67.191166                 0.031000                     NaN           8.154833            2       True         45\n",
      "20         LightGBM_r188_BAG_L1_FULL      -0.360184  -0.372207  root_mean_squared_error        0.015682            NaN   0.272045                 0.015682                     NaN           0.272045            1       True         25\n",
      "21         CatBoost_r177_BAG_L2_FULL      -0.360247  -0.363531  root_mean_squared_error        1.111540            NaN  59.594620                 0.020999                     NaN           0.558286            2       True         41\n",
      "22           CatBoost_r9_BAG_L1_FULL      -0.360811  -0.368452  root_mean_squared_error        0.019000            NaN   2.273602                 0.019000                     NaN           2.273602            1       True         16\n",
      "23              LightGBM_BAG_L2_FULL      -0.361329  -0.366367  root_mean_squared_error        1.111049            NaN  59.187359                 0.020509                     NaN           0.151026            2       True         33\n",
      "24     RandomForest_r195_BAG_L1_FULL      -0.362026  -0.385648  root_mean_squared_error        0.068277       0.232246   1.481880                 0.068277                0.232246           1.481880            1       True         24\n",
      "25         LightGBMLarge_BAG_L1_FULL      -0.362292  -0.376317  root_mean_squared_error        0.016001            NaN   0.261508                 0.016001                     NaN           0.261508            1       True         11\n",
      "26         LightGBM_r131_BAG_L2_FULL      -0.362859  -0.367039  root_mean_squared_error        1.114541            NaN  59.563353                 0.024000                     NaN           0.527020            2       True         43\n",
      "27               XGBoost_BAG_L2_FULL      -0.363122  -0.367069  root_mean_squared_error        1.118054            NaN  59.154579                 0.027514                     NaN           0.118246            2       True         38\n",
      "28  NeuralNetFastAI_r102_BAG_L1_FULL      -0.363350  -0.369438  root_mean_squared_error        0.023087            NaN   0.776776                 0.023087                     NaN           0.776776            1       True         22\n",
      "29           XGBoost_r33_BAG_L1_FULL      -0.363490  -0.378769  root_mean_squared_error        0.038515            NaN   0.254578                 0.038515                     NaN           0.254578            1       True         19\n",
      "30       RandomForestMSE_BAG_L1_FULL      -0.364180  -0.387477  root_mean_squared_error        0.142520       0.204287   1.471572                 0.142520                0.204287           1.471572            1       True          5\n",
      "31       NeuralNetFastAI_BAG_L1_FULL      -0.364209  -0.370986  root_mean_squared_error        0.038127            NaN   1.306882                 0.038127                     NaN           1.306882            1       True          8\n",
      "32        ExtraTrees_r42_BAG_L1_FULL      -0.365751  -0.389921  root_mean_squared_error        0.148520       0.222803   1.328103                 0.148520                0.222803           1.328103            1       True         20\n",
      "33         LightGBMLarge_BAG_L2_FULL      -0.366710  -0.370125  root_mean_squared_error        1.110542            NaN  59.445071                 0.020001                     NaN           0.408737            2       True         40\n",
      "34         ExtraTreesMSE_BAG_L1_FULL      -0.366910  -0.389820  root_mean_squared_error        0.073003       0.334546   1.045338                 0.073003                0.334546           1.045338            1       True          7\n",
      "35       NeuralNetFastAI_BAG_L2_FULL      -0.370311  -0.367043  root_mean_squared_error        1.134522            NaN  60.306732                 0.043981                     NaN           1.270399            2       True         37\n",
      "36  NeuralNetFastAI_r191_BAG_L2_FULL      -0.374361  -0.368171  root_mean_squared_error        1.148052            NaN  60.378957                 0.057511                     NaN           1.342623            2       True         44\n",
      "37        KNeighborsUnif_BAG_L1_FULL      -0.396449  -0.420460  root_mean_squared_error        0.024639       0.033940   0.008940                 0.024639                0.033940           0.008940            1       True          1\n",
      "38        NeuralNetTorch_BAG_L2_FULL      -0.401732  -0.399392  root_mean_squared_error        1.126541            NaN  59.389863                 0.036000                     NaN           0.353530            2       True         39\n",
      "39        KNeighborsDist_BAG_L1_FULL      -0.405543  -0.433057  root_mean_squared_error        0.019897       0.028069   0.006008                 0.019897                0.028069           0.006008            1       True          2\n",
      "40    NeuralNetTorch_r79_BAG_L2_FULL      -0.426042  -0.430323  root_mean_squared_error        1.145053            NaN  61.217161                 0.054513                     NaN           2.180828            2       True         42\n",
      "41        NeuralNetTorch_BAG_L1_FULL      -0.431073  -0.412159  root_mean_squared_error        0.025001            NaN   1.196761                 0.025001                     NaN           1.196761            1       True         10\n",
      "42    NeuralNetTorch_r79_BAG_L1_FULL      -0.442163  -0.428362  root_mean_squared_error        0.035004            NaN   4.680971                 0.035004                     NaN           4.680971            1       True         13\n",
      "43    NeuralNetTorch_r22_BAG_L1_FULL      -0.445441  -0.457922  root_mean_squared_error        0.031001            NaN  10.513824                 0.031001                     NaN          10.513824            1       True         18\n",
      "44    NeuralNetTorch_r30_BAG_L1_FULL      -0.469463  -0.482001  root_mean_squared_error        0.052511            NaN   9.904162                 0.052511                     NaN           9.904162            1       True         28\n",
      "45    NeuralNetTorch_r86_BAG_L1_FULL      -0.507519  -0.513043  root_mean_squared_error        0.027999            NaN   2.082444                 0.027999                     NaN           2.082444            1       True         30\n",
      "Stacked overfitting occurred: False.\n",
      "Spend 975 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 2625 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 2625s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240209_054805\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          32\n",
      "Memory Avail:       19.92 GB / 31.75 GB (62.7%)\n",
      "Disk Space Avail:   140.28 GB / 276.64 GB (50.7%)\n",
      "===================================================\n",
      "Train Data Rows:    5343\n",
      "Train Data Columns: 19\n",
      "Label Column:       Discontinued\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    20402.85 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.99 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  2 | ['MonthlyCharges', 'TotalCharges']\n",
      "\t\t('int', [])    :  2 | ['SeniorCitizen', 'tenure']\n",
      "\t\t('object', []) : 15 | ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 10 | ['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', ...]\n",
      "\t\t('float', [])     :  2 | ['MonthlyCharges', 'TotalCharges']\n",
      "\t\t('int', [])       :  1 | ['tenure']\n",
      "\t\t('int', ['bool']) :  6 | ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t19 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.21 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1749.49s of the 2624.88s of remaining time.\n",
      "\t-0.4171\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1749.42s of the 2624.82s of remaining time.\n",
      "\t-0.4287\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1749.38s of the 2624.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t-0.3667\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1745.69s of the 2621.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t-0.3695\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1741.78s of the 2617.17s of remaining time.\n",
      "\t-0.3838\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1740.82s of the 2616.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.04%)\n",
      "\t-0.3656\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.35s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1717.67s of the 2593.07s of remaining time.\n",
      "\t-0.3876\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1717.03s of the 2592.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t-0.369\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.98s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1705.23s of the 2580.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.05%)\n",
      "\t-0.3697\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1701.37s of the 2576.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t-0.4162\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.27s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1688.05s of the 2563.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.08%)\n",
      "\t-0.3767\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.87s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1683.08s of the 2558.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.04%)\n",
      "\t-0.3654\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.72s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1678.2s of the 2553.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t-0.428\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.02s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1651.17s of the 2526.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.04%)\n",
      "\t-0.3693\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.02s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1645.96s of the 2521.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t-0.369\t = Validation score   (-root_mean_squared_error)\n",
      "\t25.33s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 1617.32s of the 2492.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.16%)\n",
      "\t-0.3676\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.94s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 1594.25s of the 2469.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t-0.3663\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.39s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 1589.92s of the 2465.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t-0.4318\t = Validation score   (-root_mean_squared_error)\n",
      "\t36.26s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 1550.43s of the 2425.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.30%)\n",
      "\t-0.3773\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.25s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 1545.32s of the 2420.72s of remaining time.\n",
      "\t-0.386\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 1544.49s of the 2419.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t-0.3653\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.42s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 1532.21s of the 2407.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n"
     ]
    }
   ],
   "source": [
    "def minimal_numerize_csv():\n",
    "    df = pd.read_csv('train.csv').drop('customerID', axis=1)\n",
    "    df['Discontinued'] = (df['Discontinued'] == 'Yes').astype(float)\n",
    "    return df\n",
    "\n",
    "train_data = TabularDataset(minimal_numerize_csv())\n",
    "predictor = TabularPredictor(label='Discontinued', problem_type='regression').fit(train_data=train_data, presets='high_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomerID\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      2\u001b[0m y\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "y = predictor.predict(pd.read_csv('test.csv').drop('customerID', axis=1))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "write_submission(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
